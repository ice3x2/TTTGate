## TTTGate 백프레셔(Backpressure) 처리 분석 리포트

### 1. 개요

TTTGate는 대용량 데이터 전송 시 발생할 수 있는 백프레셔(Backpressure) 문제를 해결하기 위해 **파일 캐시(File Cache)** 기반의 메커니즘을 구현하고 있습니다. 이 리포트는 `FileCache`와 이를 사용하는 `SocketHandler`의 소스 코드를 분석하여, TTTGate의 백프레셔 처리 방식의 원리, 장단점, 그리고 개선 방안을 제시합니다.

### 2. 핵심 컴포넌트 분석

#### 2.1. `FileCache.ts`

`FileCache` 클래스는 메모리 버퍼가 가득 찼을 때 데이터를 디스크에 임시 저장하는 역할을 합니다.

*   **파일 생성:** 각 `SocketHandler` 인스턴스마다 별도의 캐시 파일(`.cache`)을 생성합니다. 파일명은 프로세스 ID, 타임스탬프, 난수를 조합하여 고유성을 보장합니다.
*   **데이터 저장 및 관리:**
    *   `writeSync`: 데이터를 캐시 파일에 동기적으로 기록합니다. 이때 데이터를 `CacheRecord`라는 단위로 관리하며, 각 레코드는 파일 내 위치, 길이, 용량 정보를 가집니다.
    *   **블록 재사용:** 데이터 삭제 시 해당 공간을 `_emptyBlocks` 배열에 추가하여, 새로운 데이터가 들어올 때 재사용함으로써 파일 단편화를 최소화하고 디스크 I/O를 줄입니다.
    *   `readSync`: ID를 기반으로 캐시 파일에서 데이터를 읽어옵니다.
    *   `remove`: 데이터 블록을 `_emptyBlocks`에 추가하여 재사용 가능하게 만듭니다.
*   **생명주기:** `delete` 메서드를 통해 캐시 파일을 디스크에서 완전히 삭제합니다.

#### 2.2. `SocketHandler.ts`

`SocketHandler`는 소켓 데이터 전송의 핵심 로직을 담당하며, 백프레셔 발생 시 `FileCache`를 활용합니다.

*   **백프레셔 감지:** `sendData` 메서드에서 소켓의 메모리 버퍼 크기가 설정된 임계값(`_memBufferSizeLimit` 또는 `MaxGlobalMemoryBufferSize`)을 초과하면 백프레셔가 발생한 것으로 간주합니다.
*   **백프레셔 처리:**
    1.  **파일 캐싱:** 메모리 버퍼가 가득 차면, 전송 대기 중인 데이터를 메모리 대신 `FileCache`에 저장합니다.
    2.  **대기 큐:** 전송할 데이터는 `_waitQueue` (Dequeue)에 `WaitItem` 객체로 저장됩니다. `WaitItem`은 메모리 내 버퍼 또는 파일 캐시 ID를 가집니다.
    3.  **데이터 전송 제어:**
        *   `sendPopDataRecursive2`: 대기 큐에서 데이터를 순차적으로 꺼내 소켓으로 전송합니다.
        *   **`drain` 이벤트 활용:** Node.js 소켓의 내부 버퍼가 가득 차 `write()`가 `false`를 반환하면, `_isFullNativeBuffer` 플래그를 `true`로 설정하고 데이터 전송을 일시 중단합니다. 이후 소켓 버퍼가 비워져 `drain` 이벤트가 발생하면, 중단했던 데이터 전송을 재개합니다.
    4.  **캐시 데이터 처리:** 파일 캐시에 저장된 데이터(`cacheID`가 있는 `WaitItem`)는 전송 직전에 `FileCache.readSync`를 통해 읽어온 후 소켓으로 전송되며, 전송 완료 후에는 `FileCache.remove`를 통해 캐시에서 삭제됩니다.

### 3. 분석 및 평가

#### 3.1. 장점

*   **메모리 안정성:** 메모리 버퍼가 가득 찼을 때 디스크를 활용함으로써, 대용량 데이터 전송 시 발생할 수 있는 메모리 부족(Out of Memory) 현상을 효과적으로 방지하고 애플리케이션의 안정성을 높입니다.
*   **효율적인 데이터 흐름 제어:** Node.js의 `drain` 이벤트를 적절히 활용하여 소켓의 버퍼 상태에 따라 데이터 전송 속도를 동적으로 조절하는 효율적인 백프레셔 제어 메커니즘을 구현했습니다.
*   **간결한 구현:** 파일 캐시와 대기 큐를 이용한 방식은 비교적 단순하면서도 효과적으로 백프레셔 문제를 해결합니다.

#### 3.2. 단점 및 잠재적 위험

*   **디스크 I/O 병목:** 매우 빈번하게 백프레셔가 발생하는 상황에서는 디스크 I/O가 새로운 병목 지점이 될 수 있습니다. 특히, 다수의 소켓이 동시에 파일 캐시를 사용하게 되면 디스크 경합이 발생할 수 있습니다.
*   **캐시 파일 크기:** 현재 구현에는 캐시 파일의 최대 크기 제한이 없어, 특정 상황에서는 디스크 공간을 과도하게 사용할 위험이 있습니다.
*   **단순한 블록 할당:** `FileCache`의 블록 재사용 로직은 비어있는 공간을 순차적으로 탐색하므로, 최적의 블록(best-fit)을 찾지 못해 공간 비효율을 야기할 수 있습니다.
*   **반응적 처리:** 백프레셔는 메모리 버퍼가 *이미* 가득 찼을 때 처리됩니다. 버퍼 사용량이 특정 임계치(예: 80%)에 도달했을 때 미리 캐싱을 시작하는 등, 보다 선제적인 대응 방식이 성능 향상에 도움이 될 수 있습니다.

### 4. 개선 제안

1.  **캐시 크기 제한 및 관리 정책 도입:**
    *   `FileCache`에 최대 크기 제한(maxSize) 옵션을 추가하고, 이 한도를 초과할 경우 가장 오래된 데이터(LRU)를 삭제하는 등의 정책을 구현하여 디스크 공간 사용을 제어할 수 있습니다.
2.  **선제적 백프레셔 대응:**
    *   `SocketHandler`의 메모리 버퍼 사용량이 설정된 임계치(예: 80%)를 넘으면 파일 캐싱을 시작하도록 로직을 변경하여, 백프레셔 발생을 미리 방지하고 더 부드러운 데이터 흐름을 유도할 수 있습니다.
3.  **데이터 우선순위 큐 도입:**
    *   단순 FIFO(First-In, First-Out) 방식의 `Dequeue` 대신, 제어 패킷과 같이 우선순위가 높은 데이터를 먼저 처리할 수 있는 우선순위 큐(Priority Queue)를 도입하여 중요한 통신이 지연되는 것을 방지할 수 있습니다.
4.  **에러 처리 강화:**
    *   파일 시스템 에러(예: 디스크 공간 부족, 쓰기 권한 없음) 발생 시, 이를 로깅하고 상위 로직으로 전파하여 보다 안정적으로 예외 상황을 처리하도록 보강해야 합니다.

### 5. 결론

TTTGate의 파일 캐시 기반 백프레셔 처리 메커니즘은 메모리 안정성을 확보하는 효과적인 방법입니다. 하지만 디스크 I/O, 캐시 크기 관리, 블록 할당 전략 등에서 개선의 여지가 있으며, 위에서 제안된 개선 방안들을 통해 더욱 안정적이고 효율적인 시스템으로 발전할 수 있을 것입니다.